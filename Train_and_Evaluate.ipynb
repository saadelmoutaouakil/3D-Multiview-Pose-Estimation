{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOsapaUjl6SSFpcT3eMyZfc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-6-3wH5Pni3","executionInfo":{"status":"ok","timestamp":1674390769939,"user_tz":-60,"elapsed":2965,"user":{"displayName":"Saad El Moutaouakil","userId":"16506912632543768023"}},"outputId":"593d64f1-50c8-4b39-8812-a2469f004b6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import sys\n","PROJECT_ROOT = os.path.abspath(os.curdir) ## Please make sure it outputs the correct root, No universal solution for Colab - Jupyter - Local environment\n","PROJECT_ROOT += \"/drive/MyDrive/GCN/\" \n","print('The Project is running from : ', PROJECT_ROOT)\n","sys.path.append(PROJECT_ROOT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tc9ATPuHQHAw","executionInfo":{"status":"ok","timestamp":1674390769939,"user_tz":-60,"elapsed":5,"user":{"displayName":"Saad El Moutaouakil","userId":"16506912632543768023"}},"outputId":"ac03264c-ec33-4b97-cd2b-c6dc713eebb8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["The Project is running from :  /content/drive/MyDrive/GCN/\n"]}]},{"cell_type":"markdown","source":["Code Adapted from https://github.com/garyzhao/SemGCN"],"metadata":{"id":"jvgIo7OPY-t_"}},{"cell_type":"code","source":["from __future__ import print_function, absolute_import, division\n","\n","import os\n","import time\n","import datetime\n","import argparse\n","import numpy as np\n","import os.path as path\n","import matplotlib.pyplot as plt\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import DataLoader\n","import pickle\n","\n","from progress.bar import Bar\n","from common.log import Logger, savefig\n","from common.utils import AverageMeter, lr_decay, save_ckpt\n","from common.graph_utils import adj_mx_from_skeleton\n","from common.data_utils import fetch, read_3d_data, create_2d_data\n","from common.generators import PoseGenerator,PoseGenerator_Multi\n","from common.loss import mpjpe, p_mpjpe\n","from models.sem_gcn import SemGCN\n","from models.MLP import mlp_model\n","from models.Sem_gcn_multiView import SemGCN_Concat_Non_Shared,SemGCN_Sum_Non_Shared,SemGCN_Concat_Shared,SemGCN_Sum_Shared"],"metadata":{"id":"SqDRWFFDQmZz","executionInfo":{"status":"ok","timestamp":1674390769940,"user_tz":-60,"elapsed":4,"user":{"displayName":"Saad El Moutaouakil","userId":"16506912632543768023"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","def parse_args():\n","        parser = argparse.ArgumentParser(description='PyTorch training script')\n","\n","        # General arguments\n","        parser.add_argument('-d', '--dataset', default='h36m', type=str, metavar='NAME', help='target dataset')\n","        parser.add_argument('-k', '--keypoints', default='gt', type=str, metavar='NAME', help='2D detections to use')\n","        parser.add_argument('-a', '--actions', default='*', type=str, metavar='LIST',\n","                                                help='actions to train/test on, separated by comma, or * for all')\n","        parser.add_argument('--evaluate', default=False, type=str, metavar='FILENAME',\n","                                                help='checkpoint to evaluate (file name)')\n","        parser.add_argument('-r', '--resume', default='', type=str, metavar='FILENAME',\n","                                                help='checkpoint to resume (file name)')\n","        parser.add_argument('-c', '--checkpoint', default='checkpoint', type=str, metavar='PATH',\n","                                                help='checkpoint directory')\n","        parser.add_argument('--snapshot', default=5, type=int, help='save models for every #snapshot epochs (default: 20)')\n","\n","        # Model arguments\n","        parser.add_argument('-l', '--num_layers', default=4, type=int, metavar='N', help='num of residual layers')\n","        parser.add_argument('-z', '--hid_dim', default=128, type=int, metavar='N', help='num of hidden dimensions')\n","        parser.add_argument('-b', '--batch_size', default=64, type=int, metavar='N',\n","                                                help='batch size in terms of predicted frames')\n","        parser.add_argument('-e', '--epochs', default=150, type=int, metavar='N', help='number of training epochs')\n","        parser.add_argument('--num_workers', default=2, type=int, metavar='N', help='num of workers for data loading')\n","        parser.add_argument('--lr', default=1.0e-4, type=float, metavar='LR', help='initial learning rate')\n","        parser.add_argument('--lr_decay', type=int, default=100000, help='num of steps of learning rate decay')\n","        parser.add_argument('--lr_gamma', type=float, default=0.96, help='gamma of learning rate decay')\n","        parser.add_argument('--no_max', dest='max_norm', action='store_false', help='if use max_norm clip on grad')\n","        parser.set_defaults(max_norm=True)\n","        parser.add_argument('--non_local', dest='non_local', action='store_true', help='if use non-local layers')\n","        parser.set_defaults(non_local=False)\n","        parser.add_argument('--dropout', default=0.0, type=float, help='dropout rate')\n","\n","        # Experimental\n","        parser.add_argument('--downsample', default=1, type=int, metavar='FACTOR', help='downsample frame rate by factor')\n","\n","        args,unknown = parser.parse_known_args()\n","\n","        # Check invalid configuration\n","        if args.resume and args.evaluate:\n","                print('Invalid flags: --resume and --evaluate cannot be set at the same time')\n","                exit()\n","\n","        return args\n","\n","def pickle_read(filename):\n","        with open(filename, \"rb\") as f:\n","                data = pickle.load(f)\n","        return data\n","\n","def train_mono_or_mlp(data_loader, model_pos, criterion, optimizer, device, lr_init, lr_now, step, decay, gamma, max_norm=True):\n","        batch_time = AverageMeter()\n","        data_time = AverageMeter()\n","        epoch_loss_3d_pos = AverageMeter()\n","\n","        # Switch to train mode\n","        torch.set_grad_enabled(True)\n","        model_pos.train()\n","        end = time.time()\n","\n","        bar = Bar('Train', max=len(data_loader))\n","        for i, (targets_3d, inputs_2d, _) in enumerate(data_loader):\n","                # Measure data loading time\n","                data_time.update(time.time() - end)\n","                num_poses = targets_3d.size(0)\n","                \n","                ###Flatten FOR MLP, comment if GCN\n","                # inputs_2d = torch.flatten(inputs_2d,start_dim = 1)\n","                # targets_3d = torch.flatten(targets_3d,start_dim = 1)\n","                \n","\n","                step += 1\n","                if step % decay == 0 or step == 1:\n","                        lr_now = lr_decay(optimizer, step, lr_init, decay, gamma)\n","                targets_3d, inputs_2d = targets_3d.to(device), inputs_2d.to(device)\n","                \n","                outputs_3d = model_pos(inputs_2d)\n","\n","\n","\n","                optimizer.zero_grad()\n","                loss_3d_pos = criterion(outputs_3d, targets_3d)\n","                error_threshold = 10000\n","                if(loss_3d_pos.item() > error_threshold):\n","                  print(\"Encountered bad Data in Training, skipped this batch\")\n","                  continue\n","                \n","                loss_3d_pos.backward()\n","                \n","                if max_norm:\n","                        nn.utils.clip_grad_norm_(model_pos.parameters(), max_norm=1)\n","                optimizer.step()\n","                epoch_loss_3d_pos.update(loss_3d_pos.item(), num_poses)\n","                  \n","\n","                # Measure elapsed time\n","                batch_time.update(time.time() - end)\n","                end = time.time()\n","\n","                bar.suffix = '({batch}/{size}) Data: {data:.6f}s | Batch: {bt:.3f}s | Total: {ttl:} | ETA: {eta:} ' \\\n","                                         '| Loss: {loss: .4f}' \\\n","                        .format(batch=i + 1, size=len(data_loader), data=data_time.avg, bt=batch_time.avg,\n","                                        ttl=bar.elapsed_td, eta=bar.eta_td, loss=epoch_loss_3d_pos.avg)\n","                bar.next()\n","\n","        bar.finish()\n","\n","\n","        return epoch_loss_3d_pos.avg, lr_now, step\n","\n","\n","def evaluate_mono_or_mlp(data_loader, model_pos, device):\n","        batch_time = AverageMeter()\n","        data_time = AverageMeter()\n","        epoch_loss_3d_pos = AverageMeter()\n","        epoch_loss_3d_pos_procrustes = AverageMeter()\n","\n","        # Switch to evaluate mode\n","        torch.set_grad_enabled(False)\n","        model_pos.eval()\n","        end = time.time()\n","\n","        bar = Bar('Eval ', max=len(data_loader))\n","        for i, (targets_3d, inputs_2d, _) in enumerate(data_loader):\n","                # Measure data loading time\n","                data_time.update(time.time() - end)\n","                num_poses = targets_3d.size(0)\n","\n","                ###Flatten FOR MLP, comment if MLP\n","                # inputs_2d = torch.flatten(inputs_2d,start_dim = 1)\n","                # targets_3d = torch.flatten(targets_3d,start_dim = 1)\n","\n","                inputs_2d = inputs_2d.to(device)\n","                outputs_3d = model_pos(inputs_2d).cpu()\n","                outputs_3d[:, :] -= outputs_3d[:, :1]  # Zero-centre the root (hip)\n","\n","                crit = nn.MSELoss(reduction='mean').to(device)\n","                ev_loss = crit(outputs_3d, targets_3d).item()\n","                error_threshold = 100\n","                if(ev_loss < error_threshold):\n","                  epoch_loss_3d_pos.update(ev_loss, num_poses)\n","                else :\n","                   print(\"Encountered bad Data in Evaluation, skipped this batch\")\n","\n","\n","                # Measure elapsed time\n","                batch_time.update(time.time() - end)\n","                end = time.time()\n","\n","                bar.suffix = '({batch}/{size}) Data: {data:.6f}s | Batch: {bt:.3f}s | Total: {ttl:} | ETA: {eta:} ' \\\n","                                         '| MPJPE: {e1: .4f} | P-MPJPE: {e2: .4f}' \\\n","                        .format(batch=i + 1, size=len(data_loader), data=data_time.avg, bt=batch_time.avg,\n","                                        ttl=bar.elapsed_td, eta=bar.eta_td, e1=epoch_loss_3d_pos.avg, e2=0)\n","                bar.next()\n","\n","        bar.finish()\n","        return epoch_loss_3d_pos.avg, 0\n","\n","\n","def train_multi(data_loader, model_pos, criterion, optimizer, device, lr_init, lr_now, step, decay, gamma, max_norm=True):\n","        batch_time = AverageMeter()\n","        data_time = AverageMeter()\n","        epoch_loss_3d_pos = AverageMeter()\n","\n","        # Switch to train mode\n","        torch.set_grad_enabled(True)\n","        model_pos.train()\n","        end = time.time()\n","\n","        bar = Bar('Train', max=len(data_loader))\n","        for i, (targets_3d, input_1,input_2,input_3,input_4, _) in enumerate(data_loader):\n","                # Measure data loading time\n","                data_time.update(time.time() - end)\n","                num_poses = targets_3d.size(0)\n","\n","                step += 1\n","                if step % decay == 0 or step == 1:\n","                        lr_now = lr_decay(optimizer, step, lr_init, decay, gamma)\n","                input_1,input_2,input_3,input_4 = input_1.to(device),input_2.to(device),input_3.to(device),input_4.to(device)\n","                targets_3d = targets_3d.to(device)\n","                outputs_3d = model_pos(input_1,input_2,input_3,input_4)\n","\n","                optimizer.zero_grad()\n","                loss_3d_pos = criterion(outputs_3d, targets_3d)\n","                error_threshold = 10000\n","                if(loss_3d_pos.item() > error_threshold):\n","                  print(\"Encountered bad Data in Training, skipped this batch\")\n","                  continue\n","                loss_3d_pos.backward()\n","                if max_norm:\n","                        nn.utils.clip_grad_norm_(model_pos.parameters(), max_norm=1)\n","                optimizer.step()\n","\n","                epoch_loss_3d_pos.update(loss_3d_pos.item(), num_poses)\n","\n","                # Measure elapsed time\n","                batch_time.update(time.time() - end)\n","                end = time.time()\n","\n","                bar.suffix = '({batch}/{size}) Data: {data:.6f}s | Batch: {bt:.3f}s | Total: {ttl:} | ETA: {eta:} ' \\\n","                                         '| Loss: {loss: .4f}' \\\n","                        .format(batch=i + 1, size=len(data_loader), data=data_time.avg, bt=batch_time.avg,\n","                                        ttl=bar.elapsed_td, eta=bar.eta_td, loss=epoch_loss_3d_pos.avg)\n","                bar.next()\n","\n","        bar.finish()\n","        return epoch_loss_3d_pos.avg, lr_now, step\n","\n","\n","def evaluate_multi(data_loader, model_pos, device):\n","        batch_time = AverageMeter()\n","        data_time = AverageMeter()\n","        epoch_loss_3d_pos = AverageMeter()\n","        epoch_loss_3d_pos_procrustes = AverageMeter()\n","\n","        # Switch to evaluate mode\n","        torch.set_grad_enabled(False)\n","        model_pos.eval()\n","        end = time.time()\n","\n","        bar = Bar('Eval ', max=len(data_loader))\n","        for i, (targets_3d, input_1,input_2,input_3,input_4, _) in enumerate(data_loader):\n","                # Measure data loading time\n","                data_time.update(time.time() - end)\n","                num_poses = targets_3d.size(0)\n","                input_1,input_2,input_3,input_4 = input_1.to(device),input_2.to(device),input_3.to(device),input_4.to(device)\n","                \n","                outputs_3d = model_pos(input_1,input_2,input_3,input_4).cpu()\n","                outputs_3d[:, :, :] -= outputs_3d[:, :1, :]  # Zero-centre the root (hip)\n","\n","                # epoch_loss_3d_pos.update(mpjpe(outputs_3d, targets_3d).item() * 1000.0, num_poses)\n","                # epoch_loss_3d_pos_procrustes.update(p_mpjpe(outputs_3d.numpy(), targets_3d.numpy()).item() * 1000.0, num_poses)\n","                crit = nn.MSELoss(reduction='mean').to(device)\n","                ev_loss = crit(outputs_3d, targets_3d).item()\n","                error_threshold = 10000\n","                if(ev_loss < error_threshold):\n","                  epoch_loss_3d_pos.update(ev_loss, num_poses)\n","                else :\n","                   print(\"Encountered bad Data in Evaluation, skipped this batch\")\n","                  \n","                \n","\n","                # Measure elapsed time\n","                batch_time.update(time.time() - end)\n","                end = time.time()\n","\n","                bar.suffix = '({batch}/{size}) Data: {data:.6f}s | Batch: {bt:.3f}s | Total: {ttl:} | ETA: {eta:} ' \\\n","                                         '| MPJPE: {e1: .4f} | P-MPJPE: {e2: .4f}' \\\n","                        .format(batch=i + 1, size=len(data_loader), data=data_time.avg, bt=batch_time.avg,\n","                                        ttl=bar.elapsed_td, eta=bar.eta_td, e1=epoch_loss_3d_pos.avg, e2=epoch_loss_3d_pos_procrustes.avg)\n","                bar.next()\n","\n","        bar.finish()\n","        return epoch_loss_3d_pos.avg, 0\n","\n","\n","\n"],"metadata":{"id":"D4Z686dOPqwz","executionInfo":{"status":"ok","timestamp":1674390769940,"user_tz":-60,"elapsed":4,"user":{"displayName":"Saad El Moutaouakil","userId":"16506912632543768023"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["adj_matrix = torch.tensor([[0.2500, 0.2500, 0.0000, 0.0000, 0.2500, 0.0000, 0.0000, 0.2500, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.0000, 0.0000, 0.0000, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.3333, 0.3333, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.3333,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.2000,\n","         0.2000, 0.2000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000,\n","         0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333,\n","         0.0000, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.3333, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.3333, 0.3333],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.5000]])"],"metadata":{"id":"4mBGoUR1UAZW","executionInfo":{"status":"ok","timestamp":1674390771125,"user_tz":-60,"elapsed":8,"user":{"displayName":"Saad El Moutaouakil","userId":"16506912632543768023"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def main(args):\n","        print('==> Using settings {}'.format(args))\n","\n","        print('==> Loading dataset...')\n","\n","\n","        _2d_training = pickle_read(PROJECT_ROOT+\"data/2D_CAMERA_TRAINING_FOR_3D_CAMERA.pickle\")\n","        # _3d_training_CAM = pickle_read(PROJECT_ROOT+\"data/3D_CAMERA_TRAINING_VF.pickle\")\n","        _3d_training_WORLD = pickle_read(PROJECT_ROOT+\"data/3D_WORLD_TRAINING.pickle\")\n","\n","        _2d_test = pickle_read(PROJECT_ROOT+\"data/2D_CAMERA_TEST_FOR_3D_CAMERA.pickle\")\n","        # _3d_test_CAM = pickle_read(PROJECT_ROOT+\"data/3D_CAMERA_TEST_VF.pickle\")\n","        _3d_test_WORLD = pickle_read(PROJECT_ROOT+\"data/3D_WORLD_TEST.pickle\") \n","\n","        \n","\n","        actions_train = ['SomeAction1' for i in range(0,len(_3d_training_WORLD))]\n","        actions_test = ['SomeAction1' for i in range(0,len(_3d_test_WORLD))]\n","        \n","        train_loader_mono = DataLoader(PoseGenerator(_3d_training_WORLD, _2d_training, actions_train), batch_size=args.batch_size,\n","                                                            shuffle=True, num_workers=args.num_workers, pin_memory=True)\n","\n","\n","        valid_loader_mono = DataLoader(PoseGenerator(_3d_test_WORLD, _2d_test, actions_test), batch_size=args.batch_size,\n","                                                            shuffle=False, num_workers=args.num_workers, pin_memory=True)\n","        \n","        train_loader_multi = DataLoader(PoseGenerator_Multi(_3d_training_WORLD, _2d_training, actions_train), batch_size=args.batch_size,\n","                                                            shuffle=True, num_workers=args.num_workers, pin_memory=True) \n","\n","        valid_loader_multi = DataLoader(PoseGenerator_Multi(_3d_test_WORLD, _2d_test, actions_test), batch_size=args.batch_size,\n","                                                            shuffle=False, num_workers=args.num_workers, pin_memory=True)  \n","        \n","        \n","        ### Set this variable to True if using multiview methods\n","        multiview_mode = True \n","        if(multiview_mode):\n","          train = train_multi\n","          evaluate = evaluate_multi\n","          train_loader = train_loader_multi\n","          valid_loader = valid_loader_multi\n","        else : \n","          train = train_mono_or_mlp\n","          evaluate = evaluate_mono_or_mlp\n","          train_loader = train_loader_mono\n","          valid_loader = valid_loader_mono\n","\n","\n","        stride = args.downsample\n","        cudnn.benchmark = True\n","        device = torch.device(\"cuda\")\n","\n","        # Create model\n","        print(\"==> Creating model...\")\n","\n","        p_dropout = (None if args.dropout == 0.0 else args.dropout)\n","        adj = adj_matrix\n","        \n","        ## Baseline GCN Config\n","        # model_pos = SemGCN(adj, args.hid_dim, num_layers=args.num_layers, p_dropout=p_dropout,\n","        #                                      nodes_group=None).to(device)\n","\n","        ## Configuration MLP\n","        # model_pos = mlp_model(nb_hidden_layers = 1).to(device)\n","\n","        # Configuration Aggregation Sum\n","        model_pos = SemGCN_Sum_Non_Shared(adj, args.hid_dim, num_layers=args.num_layers, p_dropout=p_dropout,\n","                                             nodes_group=None).to(device)\n","\n","\n","        ## Configuration Aggregation Concatenation\n","        # model_pos = SemGCN_Concat_Non_Shared(adj, args.hid_dim, num_layers=args.num_layers, p_dropout=p_dropout,\n","        #                                      nodes_group=None).to(device)\n","\n","        print(\"==> Total parameters: {:.2f}M\".format(sum(p.numel() for p in model_pos.parameters()) / 1000000.0))\n","\n","        criterion = nn.MSELoss(reduction='mean').to(device)\n","        optimizer = torch.optim.Adam(model_pos.parameters(), lr=args.lr)\n","\n","\n","        # Optionally resume from a checkpoint\n","        if args.resume or args.evaluate:\n","                ## Set the path to the model parameters to resume from or evaluate\n","                ckpt_path = \"/content/drive/MyDrive/GCN/Final_MLP_WORLD/2023-01-19T13:45:49.676759/ckpt_best.pth.tar\"\n","\n","                if path.isfile(ckpt_path):\n","                        print(\"==> Loading checkpoint '{}'\".format(ckpt_path))\n","                        ckpt = torch.load(ckpt_path)\n","                        start_epoch = ckpt['epoch']\n","                        error_best = ckpt['error']\n","                        glob_step = ckpt['step']\n","                        lr_now = ckpt['lr']\n","                        model_pos.load_state_dict(ckpt['state_dict'])\n","                        optimizer.load_state_dict(ckpt['optimizer'])\n","                        print(\"==> Loaded checkpoint (Epoch: {} | Error: {})\".format(start_epoch, error_best))\n","\n","                        if args.resume:\n","                                ckpt_dir_path = path.dirname(ckpt_path)\n","                                logger = Logger(path.join(ckpt_dir_path, 'log.txt'), resume=True)\n","                else:\n","                        raise RuntimeError(\"==> No checkpoint found at '{}'\".format(ckpt_path))\n","        else:\n","                start_epoch = 0\n","                error_best = None\n","                glob_step = 0\n","                lr_now = args.lr\n","                ckpt_dir_path = path.join(PROJECT_ROOT+\"Final_MLP_WORLD\", datetime.datetime.now().isoformat())\n","                if not path.exists(ckpt_dir_path):\n","                  os.makedirs(ckpt_dir_path)\n","                  print('==> Making checkpoint dir: {}'.format(ckpt_dir_path))\n","                logger = Logger(os.path.join(ckpt_dir_path, 'log.txt'))\n","                logger.set_names(['epoch', 'lr', 'loss_train', 'error_eval_p1', 'error_eval_p2'])\n","\n","        if args.evaluate :\n","          ## Code for evaluation, Adapt it for GCN or MLP\n","          print(\"The evaluation loss is\", evaluate(valid_loader,model_pos,device)[0])\n","        else :\n","\n","\n","          ep_loss =[]\n","          eval_loss = []\n","          for epoch in range(start_epoch, args.epochs):\n","                  print('\\nEpoch: %d | LR: %.8f' % (epoch + 1, lr_now))\n","\n","                  # Train for one epoch\n","                  epoch_loss, lr_now, glob_step = train(train_loader, model_pos, criterion, optimizer, device, args.lr, lr_now,\n","                                                                                              glob_step, args.lr_decay, args.lr_gamma, max_norm=args.max_norm)\n","\n","                  # Evaluate\n","                  error_eval_p1, error_eval_p2 = evaluate(valid_loader, model_pos, device)\n","\n","                  ep_loss.append(epoch_loss)\n","                  eval_loss.append(error_eval_p1)\n","\n","                  # Update log file\n","                  logger.append([epoch + 1, lr_now, epoch_loss, error_eval_p1, error_eval_p2])\n","\n","                  # Save checkpoint\n","                  if error_best is None or error_best > error_eval_p1:\n","                          error_best = error_eval_p1\n","                          save_ckpt({'epoch': epoch + 1, 'lr': lr_now, 'step': glob_step, 'state_dict': model_pos.state_dict(),\n","                                              'optimizer': optimizer.state_dict(), 'error': error_eval_p1}, ckpt_dir_path, suffix='best')\n","\n","                  if (epoch + 1) % args.snapshot == 0:\n","                          save_ckpt({'epoch': epoch + 1, 'lr': lr_now, 'step': glob_step, 'state_dict': model_pos.state_dict(),\n","                                              'optimizer': optimizer.state_dict(), 'error': error_eval_p1}, ckpt_dir_path)\n","\n","          logger.close()\n","\n","          # create figure and axis objects with subplots()\n","          fig,ax = plt.subplots()\n","          # make a plot\n","          ax.plot(\n","                  ep_loss,\n","                  color=\"red\")\n","          # set x-axis label\n","          ax.set_xlabel(\"epoch\", fontsize = 14)\n","          # set y-axis label\n","          ax.set_ylabel(\"Train loss\",\n","                        color=\"red\",\n","                        fontsize=14)\n","          # twin object for two different y-axis on the sample plot\n","          ax2=ax.twinx()\n","          # make a plot with different y-axis using second axis object\n","          ax2.plot(eval_loss,color=\"blue\")\n","          ax2.set_ylabel(\"Evaluation loss\",color=\"blue\",fontsize=14)\n","          plt.show()\n","          # save the plot as a file\n","          fig.savefig(path.join(ckpt_dir_path, 'logAdapted.png'),\n","                      format='jpeg',\n","                      dpi=100,\n","                      bbox_inches='tight')\n","          return\n","\n"],"metadata":{"id":"Vw3gB31wQsDb","executionInfo":{"status":"ok","timestamp":1674390905943,"user_tz":-60,"elapsed":414,"user":{"displayName":"Saad El Moutaouakil","userId":"16506912632543768023"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["main(parse_args())"],"metadata":{"id":"iD9Uo-HmQyFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5UYUxTC2fISW","executionInfo":{"status":"aborted","timestamp":1674390885024,"user_tz":-60,"elapsed":9,"user":{"displayName":"Saad El Moutaouakil","userId":"16506912632543768023"}}},"execution_count":null,"outputs":[]}]}